# -*- coding: utf-8 -*-
"""Windproject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X5IV8ol1ic3YqWC-jCnBbDJ1L3C0XVC5
"""

import pandas as pd
df = pd.read_csv('data.csv')
print(df.head())



# imported the dataset, extracted only
#DateTime
#TotalActivepower (more important than total reactive power)
#Temperatureinsidenacelle (more significant than temperature outside)
#Winddirectionoutsidenacelle (wind direction)
#WindSpeedOutsideNacelle (wind speed)

df = pd.read_csv('data.csv', names=['DateTime', 'TotalActivepower', 'Temperatureinsidenacelle', 'Winddirectionoutsidenacelle', 'WindSpeedOutsideNacelle'])

from pandas import DataFrame
from pandas import Series
from pandas import concat
from pandas import read_csv
from pandas import datetime
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from math import sqrt
from matplotlib import pyplot
import numpy as np
import pandas as pd

window_size = 24
batch_size_exp = 1
epoch_exp = 10
neurons_exp = 50
predict_values_exp = 8760
lag_exp=24

def timeseries_to_supervised(data, lag=1):
    # Create a DataFrame from the input data
    df = DataFrame(data)

    # Create lagged columns for each time step up to the specified lag
    columns = [df.shift(i) for i in range(1, lag + 1)]

    # Append the original data as the last column
    columns.append(df)

    # Concatenate the lagged columns and the original data horizontally
    df = concat(columns, axis=1)

    # Fill any NaN (missing) values with 0
    df.fillna(0, inplace=True)

    # Return the resulting DataFrame in supervised format
    return df

def difference(dataset, interval=1):
    # Create an empty list to store the differenced values
    diff = list()

    # Iterate through the dataset, starting from the specified interval
    for i in range(interval, len(dataset)):
        # Compute the difference between the current value and the value 'interval' steps back
        value = dataset[i] - dataset[i - interval]

        # Append the difference to the 'diff' list
        diff.append(value)

    # Return the differenced series as a Pandas Series
    return Series(diff)

def inverse_difference(history, yhat, interval=1):
    # Calculate the undifferenced value by adding 'yhat' to the last 'interval' value in 'history'
    return yhat + history[-interval]

from sklearn.preprocessing import MinMaxScaler

def scale(train, test):
    # Initialize the scaler
    scaler = MinMaxScaler(feature_range=(-1, 1))

    # Fit the scaler on the training data
    scaler = scaler.fit(train)

    # Transform the training data
    train_scaled = scaler.transform(train)

    # Transform the testing data
    test_scaled = scaler.transform(test)

    # Return the scaler along with the scaled training and testing data
    return scaler, train_scaled, test_scaled

from sklearn.preprocessing import MinMaxScaler

def scale(data_norm):
    # Initialize the scaler
    scaler = MinMaxScaler(feature_range=(-1, 1))

    # Fit the scaler on the input data
    scaler = scaler.fit(data_norm)

    # Transform the input data
    data_norm = data_norm.reshape(data_norm.shape[0], data_norm.shape[1])
    data_scaled = scaler.transform(data_norm)

    # Return the scaler object and the scaled data
    return scaler, data_scaled

def invert_scale(scaler, X, value):
    # Create a new row by combining the input features (X) and the scaled value (value)
    new_row = [x for x in X] + [value]

    # Convert the new row into a NumPy array
    array = np.array(new_row)

    # Reshape the array to have one row and the same number of columns as the original data
    array = array.reshape(1, len(array))

    # Invert the scaling transformation using the provided scaler
    inverted = scaler.inverse_transform(array)

    # Extract and return the original (unscaled) value
    return inverted[0, -1]

from keras.layers import Activation, Dense, BatchNormalization, TimeDistributed
from keras.models import Sequential
from keras.layers import LSTM

def fit_lstm(train, batch_size, nb_epoch, neurons):
    # Split the training data into input features (X) and target variable (y)
    X, y = train[:, 0:-1], train[:, -1]

    # Reshape the input features to match the input shape expected by the LSTM model
    X = X.reshape(X.shape[0], 1, X.shape[1])

    # Create a Sequential model (a linear stack of layers)
    model = Sequential()

    # Add an LSTM layer to the model
    model.add(LSTM(neurons_exp, dropout=0.1, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))

    # Add a BatchNormalization layer to normalize the output of the LSTM
    model.add(BatchNormalization())

    # Add a Dense layer with 50 units and ReLU activation
    model.add(Dense(50))
    model.add(Activation('relu'))

    # Add another Dense layer with 50 units and tanh activation
    model.add(Dense(50))
    model.add(Activation('tanh'))

    # Add the output layer with 1 unit (for regression) and compile the model
    model.add(Dense(1))
    model.compile(loss='mean_squared_error', optimizer='adam')

    # Train the model for the specified number of epochs
    for i in range(nb_epoch):
        model.fit(X, y, epochs=1, batch_size=batch_size, verbose=1, shuffle=False)
        model.reset_states()

    # Return the trained model
    return model

# Read the CSV file
series = pd.read_csv('data.csv')

# The rest of your code continues from here
# transform data to be stationary
raw_values = series.values
# Rest of your data preprocessing and modeling steps...

# Compute the differenced time series
diff_values = difference(raw_values, 1)

# transform data to be supervised learning
supervised = timeseries_to_supervised(diff_values, lag_exp)
supervised_values = supervised.values

# split data into train and test-sets
scaler, supervised_values = scale(supervised_values)
train_scaled, test_scaled = supervised_values[0:-predict_values_exp], supervised_values[-predict_values_exp:]
# fit the model
lstm_model = fit_lstm(train_scaled, batch_size_exp, epoch_exp, neurons_exp)

# Commented out IPython magic to ensure Python compatibility.
from math import sqrt
from numpy import concatenate
from matplotlib import pyplot
import pandas as pd
from datetime import datetime
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error
import numpy as np
import seaborn as sns
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
import glob
from datetime import datetime
# %matplotlib inline

dataframe = pd.read_csv('data.csv',index_col="DateTime")
dataframe.head()

selected_columns = df['DateTime', 'TotalActivepower', 'Temperatureinsidenacelle', 'Winddirectionoutsidenacelle', 'WindSpeedOutsideNacelle']

